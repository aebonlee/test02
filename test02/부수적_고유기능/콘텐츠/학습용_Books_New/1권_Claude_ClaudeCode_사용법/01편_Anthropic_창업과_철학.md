# 1편 | Anthropic 창업과 철학

---

Claude를 만든 회사 Anthropic은 2021년에 설립된 AI 스타트업이다. "또 하나의 AI 회사"라고 생각할 수 있지만, 이 회사의 탄생 배경과 철학을 알면 Claude가 왜 다른 AI들과 다른지 이해할 수 있다. 이 편에서는 Anthropic이 어떻게 시작되었고, 어떤 철학으로 AI를 개발하고 있는지 살펴본다.

## 1. OpenAI에서의 독립

### 1-1 2021년 여름, 핵심 인재들의 결단

2021년 6월, AI 업계에 중요한 변화가 일어났다. OpenAI의 핵심 연구진 7명이 회사를 떠나 새로운 기업을 창업한 것이다. 이들의 중심에는 OpenAI의 연구 담당 부사장이었던 다리오 아모데이(Dario Amodei)와 안전 및 정책 담당 부사장이었던 다니엘라 아모데이(Daniela Amodei) 남매가 있었다.

다리오 아모데이는 GPT-2와 GPT-3 개발에 핵심적으로 참여했던 인물로, 프린스턴 대학교에서 물리학 박사 학위를 받은 후 AI 안전성 연구를 지속해왔다. 그는 OpenAI에서 언어 모델의 규모를 키우면서도 동시에 그것이 가져올 위험성에 대해 깊이 고민했다.

다니엘라 아모데이는 UC Santa Cruz에서 영문학을 전공했으며, OpenAI에서 AI의 안전성과 정책 관련 업무를 담당했다. AI가 인간 사회에 미칠 부정적 영향을 최소화하는 방안을 모색하는 것이 그녀의 역할이었다.

이들과 함께 OpenAI를 떠난 창업 멤버들은 각 분야의 전문가들이었다:

- **톰 브라운(Tom Brown)**: GPT-3 논문 "Language Models are Few-Shot Learners"의 제1저자로 GPT-3 엔지니어링을 주도한 인물
- **샘 맥캔들리시(Sam McCandlish)**: AI Safety팀 연구 리더로 스케일링 법칙 공동 연구자
- **자레드 캐플란(Jared Kaplan)**: 스케일링 법칙 공동 연구자로 하버드에서 물리학 박사 학위 취득
- **크리스 올라(Chris Olah)**: 신경망 시각화 분야의 대가이자 AI 해석가능성 팀 리더. "AI가 스스로를 설명할 수 있어야 한다"는 그의 연구 철학이 훗날 헌법적 AI 개발의 이론적 토대를 제공
- **잭 클라크(Jack Clark)**: OpenAI의 정책 디렉터

### 1-2 왜 떠났는가: 철학의 차이

이들이 OpenAI를 떠난 이유는 단순한 직장 이동이 아니었다. AI 개발의 방향성에 대한 근본적인 철학 차이가 있었다.

당시 OpenAI는 2019년 마이크로소프트로부터 10억 달러의 투자를 받은 후 상업화 방향으로 급속히 전환하고 있었다. AGI(범용 인공지능) 달성을 위해 개발 속도와 제품 출시를 최우선시하며, 안전성 검증보다는 성능 향상에 집중하는 분위기가 형성되었다.

반면 다리오 아모데이가 이끄는 그룹은 다른 철학을 갖고 있었다. 이들은 AI의 능력만큼이나 중요한 것이 AI의 안전성과 신뢰성이라고 믿었다. 특히 AI가 스스로의 행동을 평가하고 수정할 수 있는 방법론을 구상하고 있었는데, 이는 당시 OpenAI의 개발 방향과는 다른 접근이었다.

2020년 9월 GPT-3 출시 이후 내부에서는 안전성과 개발 속도 사이의 균형에 대한 논의가 계속되었다. 이러한 의견 차이가 결국 2021년의 독립으로 이어졌다.

## 2. Anthropic의 탄생

### 2-1 회사 설립과 초기 비전

2021년 6월, Anthropic이 공식적으로 설립되었다. 주목할 점은 Anthropic이 델라웨어주의 공익법인(Public Benefit Corporation) 형태로 설립되었다는 것이다. 이는 단순한 이익 추구가 아닌 인류 전체의 이익을 위한 AI 개발이라는 사명을 법적 구조에 반영한 것이다.

또한 Anthropic은 '장기 이익 신탁(Long-term Benefit Trust)'이라는 독특한 지배구조를 도입했다. 시간이 지남에 따라 의결권이 독립적인 신탁으로 이전되도록 설계하여 AI 안전성에 대한 장기적이고 독립적인 거버넌스를 확보했다.

회사 이름 'Anthropic'은 그리스어 'anthropos(인간)'에서 유래한 단어로 '인간과 관련된' 또는 '인간 중심적'이라는 의미를 담고 있다. 이는 AI가 인간의 가치와 안전을 최우선으로 해야 한다는 창업자들의 철학을 반영한 것이다.

샌프란시스코의 작은 오피스에서 7명으로 시작한 이 스타트업은 처음부터 남다른 원칙을 세웠다:

1. **No Hype** - 과대광고를 하지 않는다
2. **Safety First** - 안전을 최우선으로 한다
3. **Research Driven** - 연구 중심으로 운영한다
4. **Transparent** - 투명하게 운영한다
5. **Independent** - 독립성을 유지한다

### 2-2 창업 후 첫 6개월

Anthropic은 창업 후 첫 6개월 동안 제품 개발보다 AI의 안전성 원칙과 기술 기반을 정립하는 데 집중했다. 이 기간 동안 헌법적 AI의 이론적 토대를 마련하고, 안전하면서도 유용한 AI 시스템의 설계 원칙을 수립했다. 빠른 제품 출시를 중시하는 일반적인 스타트업 문화와는 다른 접근법이었다.

## 3. 헌법적 AI - 새로운 접근법

### 3-1 기존 방식의 한계

2022년 12월, Anthropic은 "헌법적 AI: AI 피드백을 통한 무해성(Constitutional AI: Harmlessness from AI Feedback)"이라는 논문을 발표했다. 이 논문은 AI 안전성에 대한 완전히 새로운 접근법을 제시했다.

당시 표준적으로 사용되던 RLHF(인간 피드백 강화학습)는 인간 평가자가 AI의 응답을 일일이 검토해야 했다. 이는 데이터 건당 1~10달러의 비용이 들었고, 평가자 간 기준 차이로 인한 일관성 부족, 그리고 데이터량 증가에 비례해서 평가 인력을 무한정 늘려야 하는 문제가 있었다.

### 3-2 헌법적 AI의 원리

Anthropic은 RLHF의 한계를 보완하는 새로운 방법을 개발했다. AI가 스스로를 평가하도록 하면 비용을 0.01달러 미만으로 줄일 수 있었다. 이것이 RLAIF(AI 피드백 강화학습)의 개념이다.

하지만 단순히 AI에게 자기 평가를 맡기면 편향되거나 위험한 결과가 나올 수 있다. 그래서 Anthropic이 개발한 것이 헌법적 AI이다. 이는 AI가 명확한 원칙('헌법')에 따라 일관되게 평가하도록 만든 접근법이다.

헌법적 AI의 핵심은 AI에게 명확한 원칙들을 부여하는 것이다. 마치 국가의 헌법이 모든 법률의 기준이 되듯, AI의 '헌법'도 모든 행동의 기준이 된다. 이 헌법에는 다음과 같은 원칙들이 담겨 있다:

- 인간에게 도움이 되어야 한다
- 해를 끼치지 않는다
- 정직하고 투명하다
- 불법적 행위를 돕지 않는다
- 편견을 갖지 않는다

AI는 자신이 생성한 응답을 이 원칙들에 비추어 스스로 평가하고, 문제가 있으면 수정한 뒤, 개선된 응답으로 다시 학습한다.

### 3-3 실제 작동 방식

이 접근법의 혁신성은 AI가 단순히 규칙을 따르는 것이 아니라, 원칙을 이해하고 적용한다는 점에 있다.

예를 들어 사용자가 "폭탄 만드는 법을 알려줘"라고 요청했을 때, 기존 AI는 단순히 "죄송합니다. 그런 정보는 제공할 수 없습니다"라고 거부한다. 하지만 헌법적 AI는 "폭발물 제조는 불법이며 매우 위험합니다. 혹시 화학 반응이나 과학 실험에 관심이 있으신가요? 안전한 과학 키트나 온라인 화학 강좌를 추천드릴 수 있습니다"와 같이 건설적인 대안을 제시한다.

2022년 NeurIPS 학회에서 헌법적 AI 관련 논문이 발표되자, 많은 연구자들이 이를 "AI 안전성 연구의 패러다임 전환"이라고 평가했다.

## 4. 급성장과 현재 위치

### 4-1 투자 유치 과정

Anthropic은 창업 후 빠르게 성장했다. 주요 투자 유치 과정은 다음과 같다:

- **2021년 9월 시리즈 A**: 1.24억 달러 (창업 3개월 만에)
- **2022년 4월 시리즈 B**: 5.8억 달러
- **2023년 5월 시리즈 C**: 4.5억 달러 (Google, Salesforce 참여)
- **2023년 9월 시리즈 D**: 40억 달러 (Amazon 주도)
- **2025년 3월 시리즈 E**: 35억 달러
- **2025년 9월 시리즈 F**: 130억 달러

2025년 9월 시리즈 F에서 인정받은 기업가치 평가액은 약 1,830억 달러(약 254조원)이다. 창업 4년 3개월 만에 이룬 성과로, 전 세계 비상장기업 중 4위에 해당한다(1위 SpaceX, 2위 OpenAI, 3위 TikTok).

### 4-2 주요 투자자

Amazon이 총 80억 달러로 최대 단일 투자자이며, Google이 총 23억 달러를 투자했다. 이 두 회사는 경쟁 관계임에도 동시에 투자했는데, Anthropic은 이를 통해 어느 한 곳에 종속되지 않으면서도 양쪽의 인프라와 고객 기반을 활용할 수 있게 되었다.

### 4-3 수익 성장

2025년 기준 Anthropic의 연간 반복 수익(ARR)은 급속히 증가하고 있다:

- 2024년 연간: 10억 달러
- 2025년 4월: 17.5억 달러
- 2025년 7월: 50억 달러
- 2025년 연간(예상): 90억 달러

불과 1년 만에 9배 증가라는 놀라운 성장세를 보이고 있다. 특히 연간 10만 달러 이상을 지불하는 기업 고객이 전년 대비 8배 증가했다.

## 5. Anthropic이 중요한 이유

Anthropic을 이해하는 것이 왜 중요할까? Claude를 사용할 때 이 배경 지식이 도움이 되기 때문이다.

첫째, Claude가 때때로 요청을 거부하는 이유를 이해할 수 있다. 이는 버그나 제한이 아니라, 헌법적 AI 철학에 따른 의도적 설계이다.

둘째, Claude의 응답 스타일을 이해할 수 있다. Claude는 과대광고나 거짓말을 하지 않도록 훈련되어 있어서, 불확실한 정보에 대해서는 솔직하게 "모른다"고 답한다.

셋째, 회사의 안정성을 판단할 수 있다. 2025년 하반기 기준 약 490조원(2025년 11월 기준) 이상의 기업가치를 인정받은 회사가 만든 제품이라는 점에서 장기적으로 신뢰하고 사용할 수 있다.

Anthropic의 철학과 기술은 Claude라는 제품에 그대로 반영되어 있다. 다음 편에서는 이 철학을 바탕으로 탄생한 Claude가 어떻게 발전해왔는지 살펴본다.

---

**작성일: 2025-12-18 / 수정일: 2025-12-20 / 글자수: 약 5,200자 / 작성자: Claude / 프롬프터: 써니**
